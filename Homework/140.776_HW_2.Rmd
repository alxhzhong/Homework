---
title: "Project 2"
author: "Alex Zhong"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r warning = FALSE, message = FALSE}
library(tidyverse)
library(tidytuesdayR)
library(here)
```

# {.tabset}
## Part 1A

Let's create a function Exp(x) that approximates $e^x$:
\[\text{Exp}(x)=1+x+\frac{x^2}{2!}+\frac{x^3}{3!}+ \cdots\]

```{r}
Exp <- function(x, k){
  # approximate exp(x) with k terms
  sum = 1
  for(i in 1:k){
    sum = sum + x^i/factorial(i)
  }
  return(sum)
  
}
```

Cool! Let's test this out.

```{r}
Exp(2.3, 50)

# check
exp(2.3)
```
And we see that the two numbers match, so our function works as intended!

## Part 1B
Now, let's create functions to calculate the mean and standard deviation of a given set of $n$ observations $x_1,x_2,...,x_n$:

\begin{align*}
   \bar{x} &= \frac{1}{n}\sum_{i=1}^n{x_i} \\
   s &= \sqrt{\frac{1}{n-1}\sum_{i=1}^n{(x_i-\bar{x})^2}}
\end{align*}

```{r}
sample_mean <- function(x){
  N = length(x)
  sample_sum = sum(x)
  return(sample_sum / N)
}

sample_sd <- function(x){
  N = length(x)
  x_mean = sample_mean(x)
  sum_sqd = sum((sapply(x, "-", x_mean))^2)
  return(sqrt(sum_sqd/(N-1)))
}
```

```{r}
# specify mean = 1.5, sd = 2.5
x = rnorm(50000, 1.5, 2.5)

# check
sample_mean(x)
sample_sd(x)
```

And we see that the means and standard deviations match, so our functions work as intended!

## Part 1C
Using these mean and standard deviation functions, let's now create a function to estimate the confidence intervals for the estimate of the mean:
```{r}
calculate_CI <- function(x, conf = 0.95){
  alpha = 1 - conf
  df = length(x) - 1
  t_score <- qt(p = alpha / 2, df = df, lower.tail = FALSE)
  se_mean <- sample_sd(x) / sqrt(length(x))
  
  x_mean = sample_mean(x)
  lower_bound = x_mean - t_score * se_mean
  upper_bound = x_mean + t_score * se_mean
  
  return(c(lower_bound = lower_bound, upper_bound = upper_bound))
}
```

To test this function, we'll create a sample x.

```{r}
x <- rnorm(1000)

# code provided by Dr. Collado-Torres
dat <- data.frame(x = x)
fit <- lm(x ~ 1, dat)
```

Then, testing on $1 - \alpha = 0.95$,

```{r}
calculate_CI(x)
confint(fit)
```

and on $1 - \alpha = 0.999$,

```{r}
calculate_CI(x, conf = 0.999)
confint(fit, level = 0.999)
```

we see that the confidence intervals match for both levels of $\alpha$, so our function works as intended!

## Part 2
First, let's import the data:

```{r}
if (!file.exists(here("data", "tuesdata_rainfall.RDS"))) {
    tuesdata <- tidytuesdayR::tt_load("2020-01-07")
    rainfall <- tuesdata$rainfall
    temperature <- tuesdata$temperature

    # save the files to RDS objects
    saveRDS(tuesdata$rainfall, file = here("data", "tuesdata_rainfall.RDS"))
    saveRDS(tuesdata$temperature, file = here("data", "tuesdata_temperature.RDS"))
}

rainfall <- readRDS(here("data", "tuesdata_rainfall.RDS"))
temperature <- readRDS(here("data", "tuesdata_temperature.RDS"))
```

Using the rainfall data, we will remove rows with missing values and join it with the temperature data set by city and date. To accomplish the join, a date column was created from year/month/day columns, and the city_name column was modified to be uppercase.

```{r}
df <- rainfall %>% 
  drop_na() %>% 
  unite("date", c(year, month, day), sep = "-", remove = FALSE) %>% 
  mutate(
    date = ymd(date),
    city_name = toupper(city_name)
    ) %>% 
  select(-c(month, day)) %>% 
  inner_join(temperature, by = join_by(city_name, date), relationship = "many-to-many")

# dimensions match those specified
dim(df)

head(df)
```

## Part 3A

Using this newly joined dataset, let's plot temperature over time.

```{r}
df %>% 
  filter(year >= 2014) %>% 
  ggplot(aes(x = date, y = temperature, color = temp_type)) +
  geom_line() +
  facet_wrap(~ city_name, ncol = 3) +
  theme_classic() +
  theme(legend.position = c(0.95, 0.1),
        legend.justification = c(1, 0),
        legend.title = element_blank(),
        panel.grid.major.y = element_line(color = "grey", linewidth = 0.05)) +
  labs(
    title = "Temperature over time in select Australian cities",
    subtitle = "Temperatures steadily fluctuate by year; Canberra has the most intra-year variation",
    x = "Year",
    y = "Temperature (Â°C)",
    caption = "Data from Australian Bureau of Meteorology \n Figure by Alex Zhong (2023)"
  ) +
  scale_color_manual(values = c("red", "blue"), labels = c("Maximum temperature", "Minimum temperature"))
```

## Part 3B

Now, let's make a function to plot a rainfall histogram for a given city and year.

This function will have two arguments: `city_name` and `year`. The function should work as follows:

1. Check that `city_name` and `year` have the correct data types (character and integer); report an error if otherwise.
2. Check that `city_name` is a valid city in the dataset; report an error if otherwise. I will allow all capitalizations since we usually don't type in all caps. 
3. Check that the `city_name`/`year` combination exists in our data; report an error if otherwise.
4. Filter by `city_name`/`year`
5. Create the histogram using the filtered dataset

In creating this function, I found that filtering first helps me check to see if the city/year combo exists, so I switched the order of the two steps from what was outlined above.

Upon the suggestion of a peer (Josh Stim), I also included information about the number/percent of observations that had 0 rainfall, since the log() transform removes these from the histogram.

```{r}
plot_rainfall <- function(city_name, year){
  # check for argument datatype
  stopifnot(is.character(city_name), year%%1 == 0)
  
  # check for valid city name
  city_name = toupper(city_name)
  if(!(city_name %in% unique(df$city_name))){
    stop("The city name must be a valid city within the dataset: 
         Brisbane, Canberra, Melbourne, Perth, or Sydney.")
  }
  
  # filter by city & year
  entry <- df %>% 
    filter(city_name == !!city_name, year == !!year)
  
  # check for valid city/year combination
  # provide min/max values for city entered
  if(nrow(entry) == 0){
    valid_years <- df %>% 
      filter(city_name == !!city_name) %>% 
      pull(year) %>% 
      unique()
    stop("The city/year combination was not found in this dataset.
         The valid years for the city entered range from ", min(valid_years), " to ", max(valid_years), ".")
  }
  
  # check number of days with 0 measured rainfall, since log(0) is undefined and will not be plotted
  num_zero <- entry %>% 
    filter(rainfall == 0) %>% 
    nrow()
  perc_zero <- round(num_zero/nrow(entry) * 100, 2)
  
  # plot histogram
  entry %>% 
    ggplot(aes(log(rainfall))) +
    geom_histogram() +
    theme_classic() +
    # no caption, since we don't know what this plot looks like ahead of time
    labs(
      title = paste("Log-rainfall distribution in", str_to_title(city_name), "in", year),
      subtitle = paste0(num_zero, " days with 0 mm rainfall (", perc_zero, "% of measurements)", sep = ""),
      x = "Log(rainfall (mm))"
    )
}
```

Now, I'll test out this function:

```{r}
# test wrong data type
try(plot_rainfall(2000, "Melbourne"))

# test wrong city
try(plot_rainfall("Adelaide", 2018))

# test wrong city/year combo
try(plot_rainfall("perth", 1900))

# an example plot
plot_rainfall("perth", 1995)
```

## Part 4

### Part A

```{r}
rain_df <- df %>% 
  filter(year >= 2014) %>% 
  group_by(city_name, year) %>% 
  summarize(
    mean_rf = sample_mean(rainfall),
    sd_rf = sample_sd(rainfall),
    lower_bound = calculate_CI(rainfall)[1],
    upper_bound = calculate_CI(rainfall)[2]
  )

head(rain_df)
```
### Part B

```{r}
rain_df %>% 
  ggplot(mapping = aes(x = year, y = mean_rf)) +
  geom_point() +
  geom_line() +
  geom_errorbar(aes(ymin = lower_bound, ymax = upper_bound), width = 0.2) +
  facet_wrap(~city_name, nrow = 2) +
  theme_classic() +
  labs(
    title = "Daily mean rainfall in select Australian cities",
    subtitle = "Perth is wettest city, Canberra is driest city; No consistent inter-year pattern in rainfall",
    x = "Year",
    y = "Mean rainfall (mm)",
    caption = "Data from Australian Bureau of Meteorology \n Figure by Alex Zhong (2023) \n Note: 2019 data is incomplete"
  ) +
  scale_x_continuous(labels = c("2014", "'15", "'16", "'17", "'18", "'19"))
```

### A note

While the the mean of rainfall is technically interpreted as a daily mean rainfall, we note that the data are missing many days of the year for some cities (see plot below), so these numbers may not match well to the actual daily mean rainfalls for these cities.

```{r}
df %>%
  filter(year >= 2014) %>% 
  group_by(city_name, year) %>% 
  # divide count by 2, since we have 2 observations per day (1 min temp and 1 max temp)
  summarize(count = n()/2) %>% 
  ggplot(aes(x = year, y = count, color = city_name)) +
  geom_line(linewidth = 1.5) +
  geom_hline(aes(yintercept = 365), linetype = "dashed") +
  theme_classic() +
  labs(
    title = "Weather observation count in select Australian cities by year",
    subtitle = "Lots of missing days for Melbourne and Perth",
    color = "City",
    caption = "Data from Australian Bureau of Meteorology \n Figure by Alex Zhong (2023) \n Note: 2019 data is incomplete"
  ) +
  scale_y_continuous(breaks = c(100,200,300,365,400))
```

(another note that Brisbane has 2 weather stations contributing data, which explains why there are >365 observations in 2014)

## R session info
```{r}
options(width = 120)
sessioninfo::session_info() 
```

