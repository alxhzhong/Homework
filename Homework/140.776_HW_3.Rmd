---
title: "Project 3"
author: "Alex Zhong"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r warning = FALSE, message = FALSE}
library(tidyverse)
library(tidytuesdayR)
library(here)
library(tidytext)
library(wordcloud)
```

# {.tabset}

## Setup
```{r}
if (!file.exists(here("data", "b_lyrics.RDS"))) {
    b_lyrics <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/beyonce_lyrics.csv")
    ts_lyrics <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/taylor_swift_lyrics.csv")
    sales <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-29/sales.csv")

    # save the files to RDS objects
    saveRDS(b_lyrics, file = here("data", "b_lyrics.RDS"))
    saveRDS(ts_lyrics, file = here("data", "ts_lyrics.RDS"))
    saveRDS(sales, file = here("data", "sales.RDS"))
}

b_lyrics <- readRDS(here("data", "b_lyrics.RDS"))
ts_lyrics <- readRDS(here("data", "ts_lyrics.RDS"))
raw_sales <- readRDS(here("data", "sales.RDS"))
```


## Part 1 {.tabset}

### 1A
Taking a look at the `released` column, it seems that some of the release dates have some extra unnecessary information in the format (US/UK)[##].
```{r}
glimpse(raw_sales$released)
```

This can be generalized as anything between the start parentheses and end bracket: (....]. To remove this, we use a regular expression, then transform it into the date format:
```{r}
sales <- raw_sales %>% 
  mutate(released = str_remove_all(released, " \\(.*\\]") %>% 
                    mdy(.))

# we can also use the more specific regex " \\(\\w{2}\\)\\[\\d{2}\\]"
```

Next, to make `country` a factor:
```{r}
sales <- sales %>% 
  mutate(country = factor(country) %>% 
                   fct_recode(., "WW" = "World", "FR" = "FRA"))

levels(sales$country)
```
Next, to transform `sales` into units of millions of dollars:
```{r}
sales <- sales %>% mutate(sales = sales / 1e6L)
```

and finally, only keeping album sales from the UK, US, or the world:
```{r}
sales <- sales %>%
  filter(country %in% c("US", "UK", "WW"))

sales
```

### 1B
```{r}
sales %>% 
  filter(country == "US") %>% 
  group_by(artist) %>% 
  mutate(
    years_since_release = interval(lag(released), released) %>% 
                          as.duration(.) %>% 
                          as.numeric(., "years") %>% 
                          floor()
  ) %>% 
  summarize(
    oldest = year(min(released)),
    most_recent = year(max(released)),
    med_years_since_release = median(years_since_release, na.rm = TRUE)
  )
```

### 1C

```{r}
sales %>% 
  group_by(artist, country) %>% 
  summarize(total_sales = sum(sales)) %>% 
  ggplot(aes(x = artist, y = total_sales, fill = country)) +
  geom_bar(position = "fill", stat = "identity") +
  scale_y_continuous(labels = scales::percent) +
  theme_classic() +
  labs(
    title = "Studio album sales breakdown by artist",
    subtitle = "Proportionally, BeyoncÃ© makes more from worldwide and UK sales, \nwhile Taylor Swift makes more from US sales",
    y = "% of studio album sales"
  )
```

### 1D

```{r}
sales %>% 
  filter(country == "WW") %>% 
  mutate(title = fct_reorder(title, sales)) %>% 
  ggplot(aes(x = sales, y = title, fill = artist)) +
  geom_bar(stat = "identity") +
  theme_classic() +
  labs(
    x = "Global album sales (in millions of dollars)",
    y = "Album title"
  )
```


### 1E

```{r}
sales %>% 
  ggplot(aes(x = released, y = sales, color = artist)) +
  geom_point() +
  facet_wrap(~country, nrow = 3)
```


## Part 2 {.tabset}

### 2A

```{r}
count_lines_with_word = function(data, word){
  lines_data <- data %>% 
    unnest_tokens(line, Lyrics, token = "lines") %>% 
    filter(str_detect(line, word))
  
  print(paste(nrow(lines_data), "lines with the word", word))
  
  return(lines_data)
}

count_lines_with_word(ts_lyrics, "hello")
count_lines_with_word(ts_lyrics, "goodbye")

```


### 2B
The Beyonce lyrics dataset already has individual lines separated out into rows, so we can just use `str_detect()` to count the number of lines with "hello" or "goodbye":
```{r}
b_lyrics %>% 
  filter(str_detect(line, "hello"))

b_lyrics %>% 
  filter(str_detect(line, "hello")) %>% 
  nrow()


b_lyrics %>% 
  filter(str_detect(line, "goodbye")) 


b_lyrics %>% 
  filter(str_detect(line, "goodbye")) %>% 
  nrow()
```


### 2C

```{r}
data(stop_words)

bing_sent <- get_sentiments("bing")

b_words <- b_lyrics %>% 
  unnest_tokens(word, line, token = "words") %>% 
  anti_join(stop_words) %>% 
  count(word, sort = TRUE) %>% 
  inner_join(bing_sent) %>% 
  head(25)

b_words
```

Now, let's create a bar plot of these top 25 words used by Beyonce:

```{r}
b_words %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  ggplot(aes(x = n, y = word, fill = sentiment)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Sentiments of top-25 most-used words in Beyonce lyrics",
    subtitle = "Beyonce's most-used lyrics had equally positive and negative sentiments",
    x = "Number of instances",
    y = "Word",
    caption = "By Alex Zhong (2023)\n Data from Tidy Tuesday"
  )
  
```

And a word cloud:

```{r}
b_words %>% 
  mutate(
    color = case_when(
      sentiment == "negative" ~ "#c51b7d",
      sentiment == "positive" ~ "#4d9221"
    )
  ) %>% 
  with(wordcloud(word, n, colors = color, ordered.colors = TRUE))
```


### 2D
Now, let's perform the same analysis with Taylor Swift's lyrics:

```{r}
ts_words <- ts_lyrics %>% 
  unnest_tokens(word, Lyrics, token = "words") %>% 
  anti_join(stop_words) %>% 
  count(word, sort = TRUE) %>% 
  inner_join(bing_sent) %>% 
  head(25)

ts_words
```

Plotting these words in a bar plot,
```{r}
ts_words %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  ggplot(aes(x = n, y = word, fill = sentiment)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Sentiments of top-25 most-used words in Taylor Swift lyrics",
    subtitle = "Swift's most-used lyrics are more negative than positive",
    x = "Number of instances",
    y = "Word",
    caption = "By Alex Zhong (2023)\n Data from Tidy Tuesday"
  )
```

And a word cloud:

```{r}
ts_words %>% 
  mutate(
    color = case_when(
      sentiment == "negative" ~ "#c51b7d",
      sentiment == "positive" ~ "#4d9221"
    )
  ) %>% 
  with(wordcloud(word, n, colors = color, ordered.colors = TRUE))
```

### 2E

```{r}
afinn_sent <- get_sentiments("afinn")

ts_avgsent <- ts_lyrics %>% 
  unnest_tokens(word, Lyrics, token = "words") %>% 
  anti_join(stop_words) %>% 
  group_by(Album) %>% 
  count(word) %>% 
  inner_join(afinn_sent) %>% 
  summarize(
    avg_sentiment = sum(n * value) / sum(n)
  )

ts_avgsent
```









